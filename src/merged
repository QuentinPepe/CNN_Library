/*-- #include "BatchNorm2d.h" start --*/

/*-- #include "Layer.h" start --*/

#include <memory>
#include <string>
#include <iostream>

namespace nnm {

    template<typename InputType, typename OutputType>
    class Layer {
    public:
        virtual ~Layer() = default;

        virtual OutputType forward(const InputType &input) = 0;

        virtual std::string get_name() const = 0;

        virtual size_t get_input_size() const = 0;

        virtual size_t get_output_size() const = 0;

        virtual std::unique_ptr<Layer<InputType, OutputType>> clone() const = 0;
    };

} // namespace nnm
/*-- #include "Tensor4D.h" start --*/

#include <vector>
#include <stdexcept>
#include <algorithm>
#include <cstring>
#include <immintrin.h>
#include <iostream>
#include <cmath>
#include <numeric>
/*-- #include "Matrix.h" start --*/

#include <vector>
#include <stdexcept>
#include <algorithm>
#include <cstring>
#include <immintrin.h>
#include <iostream>
#include <cmath>
#include <numeric>
/*-- #include "Vector.h" start --*/

#include <vector>
#include <stdexcept>
#include <algorithm>
#include <numeric>
#include <immintrin.h>
#include <cmath>

namespace nnm {

    class Vector {
    private:
        alignas(32) std::vector<float> data;

    public:
        explicit Vector(size_t size) : data(size) {}

        Vector(size_t size, float initial_value) : data(size, initial_value) {}

        Vector(std::initializer_list<float> init) : data(init) {}

        float &operator[](size_t index) {
            return data[index];
        }

        const float &operator[](size_t index) const {
            return data[index];
        }

        [[nodiscard]] size_t size() const {
            return data.size();
        }

        Vector operator+(const Vector &other) const {
            if (size() != other.size()) {
                throw std::invalid_argument("Vector sizes do not match for addition");
            }

            Vector result(size());
            size_t i = 0;

            // Use AVX2 operations for blocks of 8 elements
            for (; i + 8 <= size(); i += 8) {
                __m256 a = _mm256_loadu_ps(&data[i]);
                __m256 b = _mm256_loadu_ps(&other.data[i]);
                __m256 sum = _mm256_add_ps(a, b);
                _mm256_storeu_ps(&result.data[i], sum);
            }

            // Handle the remaining elements
            for (; i < size(); ++i) {
                result[i] = data[i] + other[i];
            }

            return result;
        }

        [[nodiscard]] float dot(const Vector &other) const {
            if (size() != other.size()) {
                throw std::invalid_argument("Vector sizes do not match for dot product");
            }

            __m256 sum = _mm256_setzero_ps();
            size_t i = 0;

            // Use AVX2 operations for blocks of 8 elements
            for (; i + 8 <= size(); i += 8) {
                __m256 a = _mm256_loadu_ps(&data[i]);
                __m256 b = _mm256_loadu_ps(&other.data[i]);
                sum = _mm256_add_ps(sum, _mm256_mul_ps(a, b));
            }

            // Sum the results from AVX2
            float partial_sum[8];
            _mm256_storeu_ps(partial_sum, sum);
            float dot_product = partial_sum[0] + partial_sum[1] + partial_sum[2] + partial_sum[3] +
                                partial_sum[4] + partial_sum[5] + partial_sum[6] + partial_sum[7];

            // Handle the remaining elements
            for (; i < size(); ++i) {
                dot_product += data[i] * other[i];
            }

            return dot_product;
        }

        [[nodiscard]] float norm() const {
            return std::sqrt(this->dot(*this));
        }

        Vector operator*(float scalar) const {
            Vector result(size());
            size_t i = 0;

            // Use AVX2 operations for blocks of 8 elements
            __m256 s = _mm256_set1_ps(scalar);
            for (; i + 8 <= size(); i += 8) {
                __m256 a = _mm256_loadu_ps(&data[i]);
                __m256 product = _mm256_mul_ps(a, s);
                _mm256_storeu_ps(&result.data[i], product);
            }

            // Handle the remaining elements
            for (; i < size(); ++i) {
                result[i] = data[i] * scalar;
            }

            return result;
        }

        void fill(float value) {
            size_t i = 0;

            // Use AVX2 operations for blocks of 8 elements
            __m256 v = _mm256_set1_ps(value);
            for (; i + 8 <= size(); i += 8) {
                _mm256_storeu_ps(&data[i], v);
            }

            // Handle the remaining elements
            for (; i < size(); ++i) {
                data[i] = value;
            }
        }

    };

} // namespace nnm


namespace nnm {
    class Matrix {
    private:
        std::vector<float> data;
        size_t rows;
        size_t cols;

        static constexpr size_t STRASSEN_THRESHOLD = 64;

        [[nodiscard]] Matrix multiplyAVX(const Matrix &other) const {
            if (cols != other.rows) {
                throw std::invalid_argument("Matrix dimensions do not match for multiplication");
            }
            Matrix result(rows, other.cols);
#pragma omp parallel for
            for (size_t i = 0; i < rows; ++i) {
                for (size_t j = 0; j < other.cols; j += 4) {
                    __m256d sum = _mm256_setzero_pd();
                    for (size_t k = 0; k < cols; ++k) {
                        __m256d a = _mm256_set1_pd(static_cast<double>((*this)(i, k)));
                        __m256d b = _mm256_setr_pd(
                                static_cast<double>(other(k, j)),
                                static_cast<double>(other(k, j + 1)),
                                static_cast<double>(other(k, j + 2)),
                                static_cast<double>(other(k, j + 3))
                        );
                        sum = _mm256_add_pd(sum, _mm256_mul_pd(a, b));
                    }
                    double temp[4];
                    _mm256_storeu_pd(temp, sum);
                    for (int k = 0; k < 4 && j + k < other.cols; ++k) {
                        result(i, j + k) = static_cast<float>(temp[k]);
                    }
                }
            }
            return result;
        }

        [[nodiscard]] Matrix strassen(const Matrix &other) const {
            if (rows != cols || other.rows != other.cols || rows != other.rows) {
                throw std::invalid_argument("Matrices must be square and of the same size for Strassen's algorithm");
            }

            size_t n = rows;
            if (n <= STRASSEN_THRESHOLD) {
                return multiplyAVX(other);
            }

            size_t new_size = n / 2;
            Matrix a11(new_size, new_size), a12(new_size, new_size), a21(new_size, new_size), a22(new_size, new_size);
            Matrix b11(new_size, new_size), b12(new_size, new_size), b21(new_size, new_size), b22(new_size, new_size);

            // Split matrices
            for (size_t i = 0; i < new_size; ++i) {
                for (size_t j = 0; j < new_size; ++j) {
                    a11(i, j) = (*this)(i, j);
                    a12(i, j) = (*this)(i, j + new_size);
                    a21(i, j) = (*this)(i + new_size, j);
                    a22(i, j) = (*this)(i + new_size, j + new_size);

                    b11(i, j) = other(i, j);
                    b12(i, j) = other(i, j + new_size);
                    b21(i, j) = other(i + new_size, j);
                    b22(i, j) = other(i + new_size, j + new_size);
                }
            }

            // Recursive steps
            Matrix p1 = (a11 + a22).strassen(b11 + b22);
            Matrix p2 = (a21 + a22).strassen(b11);
            Matrix p3 = a11.strassen(b12 - b22);
            Matrix p4 = a22.strassen(b21 - b11);
            Matrix p5 = (a11 + a12).strassen(b22);
            Matrix p6 = (a21 - a11).strassen(b11 + b12);
            Matrix p7 = (a12 - a22).strassen(b21 + b22);

            // Calculate result quadrants
            Matrix c11 = p1 + p4 - p5 + p7;
            Matrix c12 = p3 + p5;
            Matrix c21 = p2 + p4;
            Matrix c22 = p1 - p2 + p3 + p6;

            // Combine result
            Matrix result(n, n);
            for (size_t i = 0; i < new_size; ++i) {
                for (size_t j = 0; j < new_size; ++j) {
                    result(i, j) = c11(i, j);
                    result(i, j + new_size) = c12(i, j);
                    result(i + new_size, j) = c21(i, j);
                    result(i + new_size, j + new_size) = c22(i, j);
                }
            }

            return result;
        }

    public:
        Matrix(size_t rows, size_t cols) : rows(rows), cols(cols), data(rows * cols, 0.0f) {}

        Matrix(size_t rows, size_t cols, float value) : rows(rows), cols(cols), data(rows * cols, value) {}


        float &operator()(size_t i, size_t j) {
            return data[i * cols + j];
        }

        const float &operator()(size_t i, size_t j) const {
            return data[i * cols + j];
        }

        Matrix operator+(const Matrix &other) const {
            if (rows != other.rows || cols != other.cols) {
                throw std::invalid_argument("Matrix dimensions do not match for addition");
            }
            Matrix result(rows, cols);
            for (size_t i = 0; i < rows * cols; ++i) {
                result.data[i] = data[i] + other.data[i];
            }
            return result;
        }

        Matrix operator-(const Matrix &other) const {
            if (rows != other.rows || cols != other.cols) {
                throw std::invalid_argument("Matrix dimensions do not match for subtraction");
            }
            Matrix result(rows, cols);
            for (size_t i = 0; i < rows * cols; ++i) {
                result.data[i] = data[i] - other.data[i];
            }
            return result;
        }

        Matrix operator*(const Matrix &other) const {
            if (cols != other.rows) {
                throw std::invalid_argument("Matrix dimensions do not match for multiplication");
            }
            if (rows == cols && other.rows == other.cols && (rows & (rows - 1)) == 0) {
                return strassen(other);
            }
            return multiplyAVX(other);
        }

        void print() const {
            for (size_t i = 0; i < rows; ++i) {
                for (size_t j = 0; j < cols; ++j) {
                    std::cout << (*this)(i, j) << " ";
                }
                std::cout << std::endl;
            }
        }

        [[nodiscard]] Matrix transpose() const {
            Matrix result(cols, rows);
            for (size_t i = 0; i < rows; ++i) {
                for (size_t j = 0; j < cols; ++j) {
                    result(j, i) = (*this)(i, j);
                }
            }
            return result;
        }

        void reshape(size_t new_rows, size_t new_cols) {
            if (new_rows * new_cols != rows * cols) {
                throw std::invalid_argument(
                        "New dimensions must have the same number of elements as the original matrix");
            }
            rows = new_rows;
            cols = new_cols;
        }


        [[nodiscard]] Matrix pad(size_t pad_h, size_t pad_w) const {
            Matrix padded(rows + 2 * pad_h, cols + 2 * pad_w);
            for (size_t i = 0; i < rows; ++i) {
                for (size_t j = 0; j < cols; ++j) {
                    padded(i + pad_h, j + pad_w) = (*this)(i, j);
                }
            }
            return padded;
        }

        [[nodiscard]] Matrix subMatrix(size_t start_row, size_t start_col, size_t sub_rows, size_t sub_cols) const {
            Matrix sub(sub_rows, sub_cols);
            for (size_t i = 0; i < sub_rows; ++i) {
                for (size_t j = 0; j < sub_cols; ++j) {
                    sub(i, j) = (*this)(start_row + i, start_col + j);
                }
            }
            return sub;
        }

        [[nodiscard]] Matrix elementWiseMul(const Matrix &other) const {
            if (rows != other.rows || cols != other.cols) {
                throw std::invalid_argument("Matrix dimensions do not match for element-wise multiplication");
            }
            Matrix result(rows, cols);
            for (size_t i = 0; i < rows * cols; ++i) {
                result.data[i] = data[i] * other.data[i];
            }
            return result;
        }

        [[nodiscard]] float sum() const {
            return std::accumulate(data.begin(), data.end(), 0.0f);
        }


        [[nodiscard]] size_t getRows() const { return rows; }

        [[nodiscard]] size_t getCols() const { return cols; }

        const std::vector<float> &getData() const { return data; }

        std::vector<float> &getData() { return data; }

        Vector operator*(const Vector &vec) const {
            if (cols != vec.size()) {
                throw std::invalid_argument("Matrix and vector dimensions do not match for multiplication");
            }

            Vector result(rows);
            for (size_t i = 0; i < rows; ++i) {
                float sum = 0.0f;
                for (size_t j = 0; j < cols; ++j) {
                    sum += (*this)(i, j) * vec[j];
                }
                result[i] = sum;
            }
            return result;
        }

    };
} // namespace nnm

namespace nnm {
    class Tensor4D {
    private:
        std::vector<float> data;
        size_t batch_size, channels, height, width;

    public:
        Tensor4D(size_t batch_size, size_t channels, size_t height, size_t width)
                : batch_size(batch_size), channels(channels), height(height), width(width),
                  data(batch_size * channels * height * width, 0.0f) {}

        Tensor4D(size_t batch_size, size_t channels, size_t height, size_t width, float value)
                : batch_size(batch_size), channels(channels), height(height), width(width),
                  data(batch_size * channels * height * width, value) {}


        float &operator()(size_t n, size_t c, size_t h, size_t w) {
            return data[(n * channels * height * width) + (c * height * width) + (h * width) + w];
        }

        const float &operator()(size_t n, size_t c, size_t h, size_t w) const {
            return data[(n * channels * height * width) + (c * height * width) + (h * width) + w];
        }

        Tensor4D operator+(const Tensor4D &other) const {
            if (batch_size != other.batch_size || channels != other.channels ||
                height != other.height || width != other.width) {
                throw std::invalid_argument("Tensor dimensions do not match for addition");
            }
            Tensor4D result(batch_size, channels, height, width);
            for (size_t i = 0; i < data.size(); ++i) {
                result.data[i] = data[i] + other.data[i];
            }
            return result;
        }

        Tensor4D operator-(const Tensor4D &other) const {
            if (batch_size != other.batch_size || channels != other.channels ||
                height != other.height || width != other.width) {
                throw std::invalid_argument("Tensor dimensions do not match for subtraction");
            }
            Tensor4D result(batch_size, channels, height, width);
            for (size_t i = 0; i < data.size(); ++i) {
                result.data[i] = data[i] - other.data[i];
            }
            return result;
        }

        Tensor4D elementWiseMul(const Tensor4D &other) const {
            if (batch_size != other.batch_size || channels != other.channels ||
                height != other.height || width != other.width) {
                throw std::invalid_argument("Tensor dimensions do not match for element-wise multiplication");
            }
            Tensor4D result(batch_size, channels, height, width);
            for (size_t i = 0; i < data.size(); ++i) {
                result.data[i] = data[i] * other.data[i];
            }
            return result;
        }

        float sum() const {
            return std::accumulate(data.begin(), data.end(), 0.0f);
        }

        float max() const {
            return *std::max_element(data.begin(), data.end());
        }

        float mean() const {
            return std::accumulate(data.begin(), data.end(), 0.0f) / static_cast<float>(data.size());
        }

        void fill(float value) {
            std::fill(data.begin(), data.end(), value);
        }

        void print() const {
            for (size_t n = 0; n < batch_size; ++n) {
                std::cout << "Batch " << n << ":\n";
                for (size_t c = 0; c < channels; ++c) {
                    std::cout << "Channel " << c << ":\n";
                    for (size_t h = 0; h < height; ++h) {
                        for (size_t w = 0; w < width; ++w) {
                            std::cout << (*this)(n, c, h, w) << " ";
                        }
                        std::cout << "\n";
                    }
                    std::cout << "\n";
                }
                std::cout << "\n";
            }
        }

        Tensor4D pad(size_t pad_h, size_t pad_w) const {
            Tensor4D padded(batch_size, channels, height + 2 * pad_h, width + 2 * pad_w);
            for (size_t n = 0; n < batch_size; ++n) {
                for (size_t c = 0; c < channels; ++c) {
                    for (size_t h = 0; h < height; ++h) {
                        for (size_t w = 0; w < width; ++w) {
                            padded(n, c, h + pad_h, w + pad_w) = (*this)(n, c, h, w);
                        }
                    }
                }
            }
            return padded;
        }

        Tensor4D subTensor(size_t start_n, size_t start_c, size_t start_h, size_t start_w,
                           size_t sub_batch, size_t sub_channels, size_t sub_height, size_t sub_width) const {
            Tensor4D sub(sub_batch, sub_channels, sub_height, sub_width);
            for (size_t n = 0; n < sub_batch; ++n) {
                for (size_t c = 0; c < sub_channels; ++c) {
                    for (size_t h = 0; h < sub_height; ++h) {
                        for (size_t w = 0; w < sub_width; ++w) {
                            sub(n, c, h, w) = (*this)(start_n + n, start_c + c, start_h + h, start_w + w);
                        }
                    }
                }
            }
            return sub;
        }

        bool operator==(const Tensor4D &other) const {
            if (getBatchSize() != other.getBatchSize() || getChannels() != other.getChannels() ||
                getHeight() != other.getHeight() || getWidth() != other.getWidth()) {
                return false;
            }
            for (size_t n = 0; n < getBatchSize(); ++n) {
                for (size_t c = 0; c < getChannels(); ++c) {
                    for (size_t h = 0; h < getHeight(); ++h) {
                        for (size_t w = 0; w < getWidth(); ++w) {
                            if ((*this)(n, c, h, w) != other(n, c, h, w)) {
                                return false;
                            }
                        }
                    }
                }
            }
            return true;
        }

        Matrix channelToMatrix(const Tensor4D &tensor, size_t batch_index, size_t channel_index) {
            size_t height = tensor.getHeight();
            size_t width = tensor.getWidth();
            Matrix result(height, width);

            size_t base_offset = (batch_index * tensor.getChannels() * height * width) +
                                 (channel_index * height * width);

            const float *tensor_data = tensor.getData().data() + base_offset;

            float *matrix_data = result.getData().data();

            size_t num_elements = height * width;

            size_t i = 0;
            for (; i + 7 < num_elements; i += 8) {
                __m256 tensor_values = _mm256_loadu_ps(tensor_data + i);
                _mm256_storeu_ps(matrix_data + i, tensor_values);
            }

            for (; i < num_elements; ++i) {
                matrix_data[i] = tensor_data[i];
            }

            return result;
        }


        [[nodiscard]] Tensor4D
        pad(const std::vector<std::pair<size_t, size_t>> &padding, float constant_value = 0.0f) const {
            if (padding.size() != 4) {
                throw std::invalid_argument("Padding should be specified for all 4 dimensions");
            }

            size_t new_batch = batch_size + padding[0].first + padding[0].second;
            size_t new_channels = channels + padding[1].first + padding[1].second;
            size_t new_height = height + padding[2].first + padding[2].second;
            size_t new_width = width + padding[3].first + padding[3].second;

            Tensor4D padded(new_batch, new_channels, new_height, new_width);
            padded.fill(constant_value);

            for (size_t n = 0; n < batch_size; ++n) {
                for (size_t c = 0; c < channels; ++c) {
                    for (size_t h = 0; h < height; ++h) {
                        for (size_t w = 0; w < width; ++w) {
                            padded(n + padding[0].first,
                                   c + padding[1].first,
                                   h + padding[2].first,
                                   w + padding[3].first) = (*this)(n, c, h, w);
                        }
                    }
                }
            }

            return padded;
        }

        size_t getBatchSize() const { return batch_size; }

        size_t getChannels() const { return channels; }

        size_t getHeight() const { return height; }

        size_t getWidth() const { return width; }

        const std::vector<float> &getData() const { return data; }

        std::vector<float> &getData() { return data; }
    };
} // namespace nnm
/*-- #include "Vector.h" start --*/
#include <cmath>
#include <memory>

namespace nnm {

    class BatchNorm2d : public Layer<Tensor4D, Tensor4D> {
    private:
        size_t num_features;
        float eps;

        Vector weight;
        Vector bias;
        Vector running_mean;
        Vector running_var;

    public:
        BatchNorm2d(size_t num_features, float eps = 1e-5)
                : num_features(num_features), eps(eps),
                  weight(num_features), bias(num_features),
                  running_mean(num_features), running_var(num_features) {
        }

        void set_parameters(const Vector &weight, const Vector &bias,
                            const Vector &running_mean, const Vector &running_var) {
            if (weight.size() != num_features || bias.size() != num_features ||
                running_mean.size() != num_features || running_var.size() != num_features) {
                throw std::invalid_argument("Parameter sizes do not match num_features");
            }
            this->weight = weight;
            this->bias = bias;
            this->running_mean = running_mean;
            this->running_var = running_var;
        }

        Tensor4D forward(const Tensor4D &input) override {
            if (input.getChannels() != num_features) {
                throw std::invalid_argument("Input channel dimension doesn't match num_features");
            }

            Tensor4D output(input.getBatchSize(), num_features, input.getHeight(), input.getWidth());

            for (size_t n = 0; n < input.getBatchSize(); ++n) {
                for (size_t c = 0; c < num_features; ++c) {
                    float inv_std = 1.0f / std::sqrt(running_var[c] + eps);
                    for (size_t h = 0; h < input.getHeight(); ++h) {
                        for (size_t w = 0; w < input.getWidth(); ++w) {
                            float normalized = (input(n, c, h, w) - running_mean[c]) * inv_std;
                            output(n, c, h, w) = normalized * weight[c] + bias[c];
                        }
                    }
                }
            }

            return output;
        }

        std::string get_name() const override {
            return "BatchNorm2d";
        }

        size_t get_input_size() const override {
            return num_features;
        }

        size_t get_output_size() const override {
            return num_features;
        }

        std::unique_ptr<Layer<Tensor4D, Tensor4D>> clone() const override {
            return std::make_unique<BatchNorm2d>(*this);
        }
    };

} // namespace nnm
/*-- #include "BatchNormalizationLayer.h" start --*/
// BatchNormalizationLayer.h

/*-- #include "Layer.h" start --*/
/*-- #include "Tensor4D.h" start --*/
/*-- #include "Vector.h" start --*/

namespace nnm {
    class BatchNormalizationLayer : public Layer<Tensor4D, Tensor4D> {
    private:
        size_t num_features;
        float epsilon;
        float momentum;
        Vector running_mean;
        Vector running_var;
        Vector gamma;
        Vector beta;

    public:
        BatchNormalizationLayer(size_t num_features, float epsilon = 1e-5, float momentum = 0.1)
                : num_features(num_features), epsilon(epsilon), momentum(momentum),
                  running_mean(num_features), running_var(num_features),
                  gamma(num_features, 1.0f), beta(num_features, 0.0f) {}

        Tensor4D forward(const Tensor4D &input) override {
            // Implémentez ici la logique de forward pass pour la normalisation par lots
            // Utilisez running_mean et running_var pour l'inférence
            // ...
            return input; // Placeholder, remplacez par la vraie implémentation
        }

        std::string get_name() const override { return "BatchNormalizationLayer"; }

        size_t get_input_size() const override { return num_features; }

        size_t get_output_size() const override { return num_features; }

        std::unique_ptr<Layer<Tensor4D, Tensor4D>> clone() const override {
            return std::make_unique<BatchNormalizationLayer>(*this);
        }
    };
}
/*-- File: ConvolutionalLayer.cpp start --*/
/*-- #include "ConvolutionalLayer.h" start --*/

/*-- #include "Layer.h" start --*/
/*-- #include "Tensor4D.h" start --*/
/*-- #include "Matrix.h" start --*/
/*-- #include "Vector.h" start --*/
#include <random>

namespace nnm {

    class ConvolutionalLayer : public Layer<Tensor4D, Tensor4D> {
    private:
        size_t in_channels, out_channels, kernel_size, stride, padding;
        Tensor4D weights;
        Vector bias;
        Tensor4D weight_gradients;
        Vector bias_gradients;

    public:
        ConvolutionalLayer(size_t in_channels, size_t out_channels, size_t kernel_size,
                           size_t stride = 1, size_t padding = 0);

        Tensor4D forward(const Tensor4D &input) override;

        [[nodiscard]] std::string get_name() const override;

        [[nodiscard]] size_t get_input_size() const override;

        [[nodiscard]] size_t get_output_size() const override;

        [[nodiscard]] std::unique_ptr<Layer<Tensor4D, Tensor4D>> clone() const override;

        void set_weights(const Tensor4D &new_weights);

        void set_bias(const Vector &new_bias);

        [[nodiscard]] const Tensor4D &get_weights() const { return weights; }

        [[nodiscard]] const Vector &get_bias() const { return bias; }

        [[nodiscard]] size_t get_padding() const { return padding; }

        [[nodiscard]] size_t get_kernel_size() const { return kernel_size; }

        [[nodiscard]] size_t get_stride() const { return stride; }

        Tensor4D get_weight_gradients();

        Vector get_bias_gradients();
    };

} // namespace nnm
#include <cmath>
#include <stdexcept>

namespace nnm {

    ConvolutionalLayer::ConvolutionalLayer(size_t in_channels, size_t out_channels, size_t kernel_size,
                                           size_t stride, size_t padding)
            : in_channels(in_channels), out_channels(out_channels), kernel_size(kernel_size),
              stride(stride), padding(padding),
              weights(out_channels, in_channels, kernel_size, kernel_size),
              bias(out_channels),
              weight_gradients(out_channels, in_channels, kernel_size, kernel_size),
              bias_gradients(out_channels) {

        // Xavier/Glorot initialization for weights
        std::random_device rd;
        std::mt19937 gen(rd());
        float limit = std::sqrt(
                6.0f / (in_channels * kernel_size * kernel_size + out_channels * kernel_size * kernel_size));
        std::uniform_real_distribution<> dis(-limit, limit);

        for (size_t o = 0; o < out_channels; ++o) {
            for (size_t i = 0; i < in_channels; ++i) {
                for (size_t h = 0; h < kernel_size; ++h) {
                    for (size_t w = 0; w < kernel_size; ++w) {
                        weights(o, i, h, w) = static_cast<float>(dis(gen));
                    }
                }
            }
        }

        // Initialize biases to zero
        for (size_t i = 0; i < out_channels; ++i) {
            bias[i] = 0.0f;
        }

        // Initialize gradients to zero
        weight_gradients.fill(0.0f);
        bias_gradients.fill(0.0f);
    }


    Tensor4D ConvolutionalLayer::forward(const Tensor4D &input) {
        size_t N = input.getBatchSize();
        size_t H = input.getHeight();
        size_t W = input.getWidth();

        size_t H_out = 1 + (H + 2 * padding - kernel_size) / stride;
        size_t W_out = 1 + (W + 2 * padding - kernel_size) / stride;

        Tensor4D output(N, out_channels, H_out, W_out);

        Tensor4D padded_input = input.pad({{0,       0},
                                           {0,       0},
                                           {padding, padding},
                                           {padding, padding}});

        for (size_t n = 0; n < N; ++n) {
            for (size_t f = 0; f < out_channels; ++f) {
                int height_index = 0;
                for (size_t i = 0; i < H; i += stride) {
                    int width_index = 0;
                    for (size_t j = 0; j < W; j += stride) {
                        Tensor4D x_slice = padded_input.subTensor(n, 0, i, j,
                                                                  1, in_channels, kernel_size, kernel_size);
                        Tensor4D w_slice = weights.subTensor(f, 0, 0, 0,
                                                             1, in_channels, kernel_size, kernel_size);
                        float sum = x_slice.elementWiseMul(w_slice).sum() + bias[f];
                        output(n, f, height_index, width_index) = sum;
                        width_index++;
                    }
                    height_index++;
                }

            }
        }

        return output;
    }

    std::string ConvolutionalLayer::get_name() const {
        return "ConvolutionalLayer";
    }

    size_t ConvolutionalLayer::get_input_size() const {
        return in_channels;
    }

    size_t ConvolutionalLayer::get_output_size() const {
        return out_channels;
    }

    void ConvolutionalLayer::set_weights(const Tensor4D &new_weights) {
        weights = new_weights;
    }

    void ConvolutionalLayer::set_bias(const Vector &new_bias) {
        bias = new_bias;
    }

    std::unique_ptr<Layer<Tensor4D, Tensor4D>> ConvolutionalLayer::clone() const {
        return std::make_unique<ConvolutionalLayer>(*this);
    }

    Tensor4D ConvolutionalLayer::get_weight_gradients() {
        return weight_gradients;
    }

    Vector ConvolutionalLayer::get_bias_gradients() {
        return bias_gradients;
    }


} // namespace nnm

/*-- File: ConvolutionalLayer.cpp end --*/
/*-- #include "ConvolutionalLayer.h" start --*/
/*-- #include "FlattenLayer.h" start --*/

/*-- #include "Layer.h" start --*/
/*-- #include "Tensor4D.h" start --*/
/*-- #include "Matrix.h" start --*/
#include <stdexcept>

namespace nnm {

    class Flatten : public Layer<Tensor4D, Matrix> {
    private:
        int start_dim;
        int end_dim;

    public:
        Flatten(int start_dim = 1, int end_dim = -1) : start_dim(start_dim), end_dim(end_dim) {}

        Matrix forward(const Tensor4D &input) override {
            size_t batch_size = input.getBatchSize();
            size_t channels = input.getChannels();
            size_t height = input.getHeight();
            size_t width = input.getWidth();

            int real_end_dim = (end_dim == -1) ? 3 : end_dim;

            if (start_dim < 0 || start_dim > 3 || real_end_dim < 0 || real_end_dim > 3 || start_dim > real_end_dim) {
                throw std::invalid_argument("Invalid start_dim or end_dim");
            }

            size_t rows = batch_size;
            size_t cols = channels * height * width;

            Matrix output(rows, cols);

            for (size_t n = 0; n < batch_size; ++n) {
                size_t index = 0;
                for (size_t c = 0; c < channels; ++c) {
                    for (size_t h = 0; h < height; ++h) {
                        for (size_t w = 0; w < width; ++w) {
                            output(n, index++) = input(n, c, h, w);
                        }
                    }
                }
            }

            return output;
        }

        std::string get_name() const override {
            return "Flatten";
        }

        size_t get_input_size() const override {
            return 0;  // Not applicable for Flatten
        }

        size_t get_output_size() const override {
            return 0;  // Not applicable for Flatten
        }

        std::unique_ptr<Layer<Tensor4D, Matrix>> clone() const override {
            return std::make_unique<Flatten>(*this);
        }
    };

} // namespace nnm
/*-- #include "FullyConnectedLayer.h" start --*/

/*-- #include "Layer.h" start --*/
/*-- #include "Tensor4D.h" start --*/
/*-- #include "Matrix.h" start --*/
/*-- #include "Vector.h" start --*/
#include <cmath>

namespace nnm {

    class FullyConnectedLayer : public Layer<Tensor4D, Matrix> {
    private:
        Matrix weights;
        Vector biases;
        size_t input_size;
        size_t output_size;

    public:
        FullyConnectedLayer(size_t input_size, size_t output_size)
                : input_size(input_size), output_size(output_size),
                  weights(input_size, output_size), biases(output_size) {
            // Initialize weights and biases (you might want to use a better initialization)
            for (size_t i = 0; i < input_size; ++i) {
                for (size_t j = 0; j < output_size; ++j) {
                    weights(i, j) = static_cast<float>(rand()) / RAND_MAX - 0.5f;
                }
            }
            for (size_t i = 0; i < output_size; ++i) {
                biases[i] = static_cast<float>(rand()) / RAND_MAX - 0.5f;
            }
        }

        Matrix forward(const Tensor4D &x) override {
            size_t N = x.getBatchSize();
            size_t D = x.getChannels() * x.getHeight() * x.getWidth();

            if (D != input_size) {
                throw std::invalid_argument("Input size doesn't match the layer's input size");
            }

            Matrix x_reshaped(N, D);
            for (size_t n = 0; n < N; ++n) {
                size_t index = 0;
                for (size_t c = 0; c < x.getChannels(); ++c) {
                    for (size_t h = 0; h < x.getHeight(); ++h) {
                        for (size_t w = 0; w < x.getWidth(); ++w) {
                            x_reshaped(n, index++) = x(n, c, h, w);
                        }
                    }
                }
            }

            Matrix fc_output = x_reshaped * weights;
            for (size_t n = 0; n < N; ++n) {
                for (size_t m = 0; m < output_size; ++m) {
                    fc_output(n, m) += biases[m];
                }
            }

            return fc_output;
        }

        std::string get_name() const override {
            return "FullyConnectedLayer";
        }

        size_t get_input_size() const override {
            return input_size;
        }

        size_t get_output_size() const override {
            return output_size;
        }

        std::unique_ptr<Layer<Tensor4D, Matrix>> clone() const override {
            return std::make_unique<FullyConnectedLayer>(*this);
        }

        void set_weights(const Matrix &new_weights) {
            if (new_weights.getRows() != input_size || new_weights.getCols() != output_size) {
                throw std::invalid_argument("New weights dimensions don't match the layer's dimensions");
            }
            weights = new_weights;
        }

        void set_biases(const Vector &new_biases) {
            if (new_biases.size() != output_size) {
                throw std::invalid_argument("New biases size doesn't match the layer's output size");
            }
            biases = new_biases;
        }

        const Matrix &get_weights() const { return weights; }

        const Vector &get_biases() const { return biases; }
    };

} // namespace nnm
/*-- #include "Layer.h" start --*/
/*-- #include "LinearLayer.h" start --*/

/*-- #include "Layer.h" start --*/
/*-- #include "Matrix.h" start --*/
/*-- #include "Vector.h" start --*/
#include <random>

namespace nnm {

    class LinearLayer : public Layer<Vector, Vector> {
    private:
        Matrix weights;
        Vector bias;
        size_t in_features;
        size_t out_features;

    public:
        LinearLayer(size_t in_features, size_t out_features)
                : in_features(in_features), out_features(out_features),
                  weights(out_features, in_features), bias(out_features) {

            // Xavier/Glorot initialization
            std::random_device rd;
            std::mt19937 gen(rd());
            std::uniform_real_distribution<> dis(-1.0 / std::sqrt(in_features), 1.0 / std::sqrt(in_features));

            for (size_t i = 0; i < out_features; ++i) {
                for (size_t j = 0; j < in_features; ++j) {
                    weights(i, j) = dis(gen);
                }
                bias[i] = 0.0f; // Initialize bias to zero
            }
        }

        Vector forward(const Vector &input) override {
            if (input.size() != in_features) {
                throw std::invalid_argument("Input size does not match layer input features");
            }
            return weights * input + bias;
        }

        std::string get_name() const override {
            return "LinearLayer";
        }

        size_t get_input_size() const override {
            return in_features;
        }

        size_t get_output_size() const override {
            return out_features;
        }

        std::unique_ptr<Layer<Vector, Vector>> clone() const override {
            return std::make_unique<LinearLayer>(*this);
        }

        const Matrix &get_weights() const {
            return weights;
        }

        const Vector &get_bias() const {
            return bias;
        }

        void set_weights(const Matrix &new_weights) {
            if (new_weights.getRows() != out_features || new_weights.getCols() != in_features) {
                throw std::invalid_argument("New weights dimensions do not match layer dimensions");
            }
            weights = new_weights;
        }

        void set_bias(const Vector &new_bias) {
            if (new_bias.size() != out_features) {
                throw std::invalid_argument("New bias size does not match layer output features");
            }
            bias = new_bias;
        }
    };

} // namespace nnm
/*-- #include "LossFunctions.h" start --*/

/*-- #include "Matrix.h" start --*/
/*-- #include "Vector.h" start --*/
#include <cmath>
#include <limits>
#include <stdexcept>

namespace nnm {

    class LossFunctions {
    public:
        struct SoftmaxLossResult {
            float loss;
            Matrix gradient;
        };

        static SoftmaxLossResult softmax_loss(const Matrix &x, const Vector &y) {
            if (x.getRows() != y.size()) {
                throw std::invalid_argument("Number of samples in x and y must match");
            }

            size_t N = x.getRows();
            size_t C = x.getCols();

            // Calculate shifted logits
            Matrix shifted_logits(N, C);
            for (size_t i = 0; i < N; ++i) {
                float max_val = -std::numeric_limits<float>::max();
                for (size_t j = 0; j < C; ++j) {
                    max_val = std::max(max_val, x(i, j));
                }
                for (size_t j = 0; j < C; ++j) {
                    shifted_logits(i, j) = x(i, j) - max_val;
                }
            }

            // Calculate sum of exp(shifted_logits)
            Vector z(N);
            for (size_t i = 0; i < N; ++i) {
                float sum = 0.0f;
                for (size_t j = 0; j < C; ++j) {
                    sum += std::exp(shifted_logits(i, j));
                }
                z[i] = sum;
            }

            // Calculate log probabilities and probabilities
            Matrix log_probs(N, C);
            Matrix probs(N, C);
            for (size_t i = 0; i < N; ++i) {
                for (size_t j = 0; j < C; ++j) {
                    log_probs(i, j) = shifted_logits(i, j) - std::log(z[i]);
                    probs(i, j) = std::exp(log_probs(i, j));
                }
            }

            // Calculate loss
            float loss = 0.0f;
            for (size_t i = 0; i < N; ++i) {
                if (y[i] < 0 || y[i] >= C) {
                    throw std::out_of_range("Label must be between 0 and C-1");
                }
                loss -= log_probs(i, static_cast<size_t>(y[i]));
            }
            loss /= N;

            // Calculate gradient
            Matrix dx = probs;
            for (size_t i = 0; i < N; ++i) {
                dx(i, static_cast<size_t>(y[i])) -= 1.0f;
            }
            for (size_t i = 0; i < N; ++i) {
                for (size_t j = 0; j < C; ++j) {
                    dx(i, j) /= N;
                }
            }

            return {loss, dx};
        }

        // You can add other loss functions here as needed
    };

} // namespace nnm
/*-- #include "Matrix.h" start --*/
/*-- #include "MaxPoolingLayer.h" start --*/

/*-- #include "Layer.h" start --*/
/*-- #include "Tensor4D.h" start --*/
#include <cmath>
#include <algorithm>

namespace nnm {

    class MaxPoolingLayer : public Layer<Tensor4D, Tensor4D> {
    private:
        size_t pooling_height;
        size_t pooling_width;
        size_t stride;

    public:
        MaxPoolingLayer(size_t pooling_height, size_t pooling_width, size_t stride)
                : pooling_height(pooling_height), pooling_width(pooling_width), stride(stride) {}

        Tensor4D forward(const Tensor4D &x) override {
            size_t N = x.getBatchSize();
            size_t F = x.getChannels();
            size_t H = x.getHeight();
            size_t W = x.getWidth();

            size_t height_pooled_out = 1 + (H - pooling_height) / stride;
            size_t width_pooled_out = 1 + (W - pooling_width) / stride;

            Tensor4D pooled_output(N, F, height_pooled_out, width_pooled_out);

            for (size_t n = 0; n < N; ++n) {
                for (size_t f = 0; f < F; ++f) {
                    for (size_t i = 0; i < height_pooled_out; ++i) {
                        for (size_t j = 0; j < width_pooled_out; ++j) {
                            size_t ii = i * stride;
                            size_t jj = j * stride;

                            float max_val = std::numeric_limits<float>::lowest();
                            for (size_t ph = 0; ph < pooling_height; ++ph) {
                                for (size_t pw = 0; pw < pooling_width; ++pw) {
                                    max_val = std::max(max_val, x(n, f, ii + ph, jj + pw));
                                }
                            }
                            pooled_output(n, f, i, j) = max_val;
                        }
                    }
                }
            }

            return pooled_output;
        }

        std::string get_name() const override {
            return "MaxPoolingLayer";
        }

        size_t get_input_size() const override {
            // This should return the input volume size, but it's not applicable for pooling layers
            return 0;
        }

        size_t get_output_size() const override {
            // This should return the output volume size, but it's not applicable for pooling layers
            return 0;
        }

        std::unique_ptr<Layer<Tensor4D, Tensor4D>> clone() const override {
            return std::make_unique<MaxPoolingLayer>(*this);
        }
    };

} // namespace nnm
/*-- #include "ReLULayer.h" start --*/

/*-- #include "Layer.h" start --*/
/*-- #include "Matrix.h" start --*/
#include <algorithm>

namespace nnm {

    class ReLULayer : public Layer<Matrix, Matrix> {
    public:
        ReLULayer() = default;

        Matrix forward(const Matrix &x) override {
            Matrix relu_output(x.getRows(), x.getCols());
            for (size_t i = 0; i < x.getRows(); ++i) {
                for (size_t j = 0; j < x.getCols(); ++j) {
                    relu_output(i, j) = std::max(0.0f, x(i, j));
                }
            }
            return relu_output;
        }

        std::string get_name() const override {
            return "ReLULayer";
        }

        size_t get_input_size() const override {
            return 0;  // ReLU doesn't change the size
        }

        size_t get_output_size() const override {
            return 0;  // ReLU doesn't change the size
        }

        std::unique_ptr<Layer<Matrix, Matrix>> clone() const override {
            return std::make_unique<ReLULayer>(*this);
        }
    };

} // namespace nnm
/*-- #include "Tensor4D.h" start --*/
/*-- #include "Vector.h" start --*/
/*-- File: main.cpp start --*/
#pragma GCC optimize("O3", "unroll-loops", "omit-frame-pointer") //Optimization flags
#pragma GCC option("arch=native", "tune=native", "no-zero-upper") //Enable AVX
#pragma GCC target("avx")  //Enable AVX

int main() {
    return 0;
}
/*-- File: main.cpp end --*/
